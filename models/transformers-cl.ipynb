{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Project(tathagataraha/contro-base)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert code here.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm, neighbors\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, BertConfig, AutoModel\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import pytorch_lightning as pl\n",
    "import neptune\n",
    "with open(\"token\", \"r\") as f:\n",
    "    token = f.read()\n",
    "neptune.init(project_qualified_name='tathagataraha/contro-base',\n",
    "             api_token=token,\n",
    "             )\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# sent_encoder = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['bert-base-uncased','roberta-base', 'vinai/bertweet-base']\n",
    "labels = ['is_cont', 'humor_rating', 'humor_controversy', 'offense_rating']\n",
    "model_num = 1\n",
    "label_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'model' : models[model_num],\n",
    "    'label' : labels[label_num],\n",
    "    'valid_size' : 0.2,\n",
    "    'rnd' : 42,\n",
    "    'max_len' : 64,\n",
    "    'train_batch' : 32,\n",
    "    'valid_batch' : 32,\n",
    "    'epochs' : 4,\n",
    "    'lr' : 1e-05,\n",
    "    'dropout' : 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'roberta-base',\n",
       " 'label': 'is_cont',\n",
       " 'valid_size': 0.2,\n",
       " 'rnd': 42,\n",
       " 'max_len': 64,\n",
       " 'train_batch': 32,\n",
       " 'valid_batch': 32,\n",
       " 'epochs': 4,\n",
       " 'lr': 1e-05,\n",
       " 'dropout': 0.1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(params['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/dataset.csv')\n",
    "import pickle\n",
    "with open('data/extracted.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# valid = pd.read_csv('data/public_dev.csv')\n",
    "# train = pd.concat([train, valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.DataFrame.from_dict(data)[['tweet_raw_text', 'task_1']].rename(columns = {'tweet_raw_text':'text', 'task_1':'is_cont'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# train_x, valid_x, train_y, valid_y = model_selection.train_test_split(train['tweet'], train['label'])\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train.text, train[params['label']], test_size=params['valid_size'], random_state=params['rnd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    try:\n",
    "        return len(text.split())\n",
    "    except:\n",
    "        print(text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19.564784053156146, 54, 0, 2709)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "maxw = 0\n",
    "large_count = 0\n",
    "for i in train.text:\n",
    "    temp = count_words(i)\n",
    "    total += temp\n",
    "    maxw = temp if temp > maxw else maxw\n",
    "    large_count += 1 if temp > 64 else 0\n",
    "total/len(train.text), maxw, large_count, len(train.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_int(i):\n",
    "    return int(i)\n",
    "train.is_cont = train.is_cont.apply(to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len, t = False):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.text\n",
    "#         self.emoji = dataframe.emoji\n",
    "#         self.hash = dataframe.segmented_hash\n",
    "        self.t = t\n",
    "        if not self.t:\n",
    "            self.targets = self.data[params['label']]\n",
    "        self.max_len = max_len\n",
    "#         print(self.targets)\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask = True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "#         h_text = self.hash[index]\n",
    "#         h_text = \" \".join(h_text)\n",
    "#         inputs = self.tokenizer.encode_plus(\n",
    "#             h_text,\n",
    "#             None,\n",
    "#             truncation=True,\n",
    "#             add_special_tokens=True,\n",
    "#             max_length=self.max_len,\n",
    "#             pad_to_max_length=True,\n",
    "#             return_attention_mask = True,\n",
    "#             return_token_type_ids=True\n",
    "#         )\n",
    "#         h_ids = inputs['input_ids']\n",
    "#         h_mask = inputs['attention_mask']\n",
    "#         h_token_type_ids = inputs[\"token_type_ids\"]\n",
    "#         h_inputs\n",
    "#         emoji = getEmojiEmbeddings(self.emoji[index])\n",
    "        if self.t:\n",
    "            return {\n",
    "                'ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'mask': torch.tensor(mask, dtype=torch.long),\n",
    "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "#                 'h_ids': torch.tensor(h_ids, dtype=torch.long),\n",
    "#                 'h_mask': torch.tensor(h_mask, dtype=torch.long),\n",
    "#                 'h_token_type_ids': torch.tensor(h_token_type_ids, dtype=torch.long),\n",
    "#                 'emoji' : torch.tensor(emoji, dtype=torch.long),\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'mask': torch.tensor(mask, dtype=torch.long),\n",
    "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "#                 'h_ids': torch.tensor(h_ids, dtype=torch.long),\n",
    "#                 'h_mask': torch.tensor(h_mask, dtype=torch.long),\n",
    "#                 'h_token_type_ids': torch.tensor(h_token_type_ids, dtype=torch.long),\n",
    "#                 'emoji' : torch.tensor(emoji, dtype=torch.long),\n",
    "                'targets': torch.tensor(self.targets[index], dtype=torch.long)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (2709, 2)\n",
      "TRAIN Dataset: (2167, 2)\n",
      "TEST Dataset: (542, 2)\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "# train_size = 0.85\n",
    "train_data=train.sample(frac=1 - params['valid_size'],random_state=params['rnd'])\n",
    "test_data=train.drop(train_data.index).reset_index(drop=True)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "# train_data, test_data = train_test_split(train, test_size=params['valid_size'])\n",
    "\n",
    "test_data=test_data.reset_index(drop=True)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(train.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_data.shape))\n",
    "\n",
    "training_set = MultiLabelDataset(train_data, tokenizer, params['max_len'])\n",
    "testing_set = MultiLabelDataset(test_data, tokenizer, params['max_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': params['train_batch'],\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': params['valid_batch'],\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModelClassifier(pl.LightningModule):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.l1 = AutoModel.from_pretrained(params['model'])\n",
    "        self.pre_classifier_1 = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(params['dropout'])\n",
    "        self.total_loss = 0\n",
    "        self.batch_count = 0\n",
    "        self.epoch = 0\n",
    "        self.classifier = torch.nn.Linear(768, 2)\n",
    "        self.preds = []\n",
    "        self.targets = []\n",
    "        self.test_preds = []\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state_1 = output_1[0]\n",
    "        pooler_1 = hidden_state_1[:, 0]\n",
    "        pooler_1 = self.pre_classifier_1(pooler_1)\n",
    "        pooler_1 = torch.nn.Tanh()(pooler_1)\n",
    "        pooler_1 = self.dropout(pooler_1)\n",
    "        output = self.classifier(pooler_1)\n",
    "        return output\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params =  self.parameters(), lr=params['lr'])\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        ids = batch['ids']\n",
    "        mask = batch['mask']\n",
    "        token_type_ids = batch['token_type_ids']\n",
    "        targets = batch['targets']\n",
    "        outputs = self.forward(ids, mask, token_type_ids)\n",
    "        loss = torch.nn.CrossEntropyLoss()(outputs, targets)\n",
    "        self.total_loss += loss\n",
    "        self.batch_count += 1\n",
    "        logger_logs = {'training_loss': loss}\n",
    "        logger_logs = {'losses': logger_logs} # optional (MUST ALL BE TENSORS)\n",
    "        output = {\n",
    "            'loss': loss, # required\n",
    "            'progress_bar': {'training_loss': loss}, # optional (MUST ALL BE TENSORS)\n",
    "            'log': logger_logs\n",
    "        }\n",
    "        # return a dict\n",
    "        return output\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.epoch += 1\n",
    "        print(f'Epoch: {self.epoch}, Loss:  {self.total_loss/self.batch_count}')\n",
    "        self.total_loss=0\n",
    "        self.batch_count=0\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        ids = batch['ids']\n",
    "        mask = batch['mask']\n",
    "        token_type_ids = batch['token_type_ids']\n",
    "        targets = batch['targets']\n",
    "        outputs = self.forward(ids, mask, token_type_ids)\n",
    "        loss = torch.nn.CrossEntropyLoss()(outputs, targets)\n",
    "        labels_hat = torch.argmax(outputs, dim=1)\n",
    "        self.preds.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "        self.targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "        val_acc = torch.sum(targets == labels_hat).item() / (len(targets) * 1.0)\n",
    "        output = {\n",
    "            'val_loss': loss,\n",
    "            'val_acc': torch.tensor(val_acc), # everything must be a tensor\n",
    "        }\n",
    "        return output\n",
    "    \n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        self.preds = list(np.argmax(np.array(self.preds), axis=1).flatten())\n",
    "        print(classification_report(self.targets, self.preds, digits=4))\n",
    "        self.preds = []\n",
    "        self.targets = []\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        ids = batch['ids']\n",
    "        mask = batch['mask']\n",
    "        token_type_ids = batch['token_type_ids']\n",
    "        outputs = self.forward(ids, mask, token_type_ids)\n",
    "        labels_hat = torch.argmax(outputs, dim=1)\n",
    "        self.test_preds.extend(labels_hat.cpu().detach().numpy().tolist())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath='/scratch/tr/',\n",
    "    filename=params['model']+'-{epoch}',\n",
    "    save_top_k = -1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    }
   ],
   "source": [
    "model = LMModelClassifier(params)\n",
    "trainer = pl.Trainer(max_epochs=params['epochs'], callbacks=[checkpoint_callback], gpus=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name             | Type         | Params\n",
      "--------------------------------------------------\n",
      "0 | l1               | RobertaModel | 124 M \n",
      "1 | pre_classifier_1 | Linear       | 590 K \n",
      "2 | dropout          | Dropout      | 0     \n",
      "3 | classifier       | Linear       | 1.5 K \n",
      "--------------------------------------------------\n",
      "125 M     Trainable params\n",
      "0         Non-trainable params\n",
      "125 M     Total params\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for validation and test dataloaders.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3906    1.0000    0.5618        25\n",
      "           1     0.0000    0.0000    0.0000        39\n",
      "\n",
      "    accuracy                         0.3906        64\n",
      "   macro avg     0.1953    0.5000    0.2809        64\n",
      "weighted avg     0.1526    0.3906    0.2195        64\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d79f1d9937419a8bac630bdd2fa53e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The {progress_bar:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
      "Please use self.log(...) inside the lightningModule instead.\n",
      "\n",
      "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
      "# (inside LightningModule)\n",
      "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
      "Please use self.log(...) inside the lightningModule instead.\n",
      "\n",
      "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
      "# (inside LightningModule)\n",
      "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9009    0.9330    0.9167       224\n",
      "           1     0.9516    0.9277    0.9395       318\n",
      "\n",
      "    accuracy                         0.9299       542\n",
      "   macro avg     0.9262    0.9304    0.9281       542\n",
      "weighted avg     0.9306    0.9299    0.9301       542\n",
      "\n",
      "Epoch: 1, Loss:  0.35507112741470337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The {progress_bar:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
      "Please use self.log(...) inside the lightningModule instead.\n",
      "\n",
      "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
      "# (inside LightningModule)\n",
      "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
      "Please use self.log(...) inside the lightningModule instead.\n",
      "\n",
      "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
      "# (inside LightningModule)\n",
      "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9383    0.9509    0.9446       224\n",
      "           1     0.9651    0.9560    0.9605       318\n",
      "\n",
      "    accuracy                         0.9539       542\n",
      "   macro avg     0.9517    0.9534    0.9525       542\n",
      "weighted avg     0.9540    0.9539    0.9539       542\n",
      "\n",
      "Epoch: 2, Loss:  0.09490055590867996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The {progress_bar:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
      "Please use self.log(...) inside the lightningModule instead.\n",
      "\n",
      "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
      "# (inside LightningModule)\n",
      "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
      "Please use self.log(...) inside the lightningModule instead.\n",
      "\n",
      "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
      "# (inside LightningModule)\n",
      "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9280    0.9777    0.9522       224\n",
      "           1     0.9837    0.9465    0.9647       318\n",
      "\n",
      "    accuracy                         0.9594       542\n",
      "   macro avg     0.9558    0.9621    0.9585       542\n",
      "weighted avg     0.9606    0.9594    0.9595       542\n",
      "\n",
      "Epoch: 3, Loss:  0.048472046852111816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The {progress_bar:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
      "Please use self.log(...) inside the lightningModule instead.\n",
      "\n",
      "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
      "# (inside LightningModule)\n",
      "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
      "Please use self.log(...) inside the lightningModule instead.\n",
      "\n",
      "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
      "# (inside LightningModule)\n",
      "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9471    0.9598    0.9534       224\n",
      "           1     0.9714    0.9623    0.9668       318\n",
      "\n",
      "    accuracy                         0.9613       542\n",
      "   macro avg     0.9593    0.9610    0.9601       542\n",
      "weighted avg     0.9614    0.9613    0.9613       542\n",
      "\n",
      "Epoch: 4, Loss:  0.03261565789580345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader=training_loader, val_dataloaders=testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.read_csv('data/final_golden.csv')\n",
    "with open('data/extracted_golden.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "test = pd.DataFrame.from_dict(data)[['tweet_raw_text', 'task_1']].rename(columns = {'tweet_raw_text':'text', 'task_1':'is_cont'})\n",
    "test['is_cont'] = testdf['is_cont']\n",
    "test.is_cont = test.is_cont.apply(to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test['is_cont'] == testdf['is_cont']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e28c9b920f4efa9d3c6a1086621dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8655    0.4728    0.6116       313\n",
      "           1     0.5429    0.8950    0.6759       219\n",
      "\n",
      "    accuracy                         0.6466       532\n",
      "   macro avg     0.7042    0.6839    0.6437       532\n",
      "weighted avg     0.7327    0.6466    0.6380       532\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dbf7e1269b14976a3d6b96b1a8efa21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7826    0.5751    0.6630       313\n",
      "           1     0.5596    0.7717    0.6488       219\n",
      "\n",
      "    accuracy                         0.6560       532\n",
      "   macro avg     0.6711    0.6734    0.6559       532\n",
      "weighted avg     0.6908    0.6560    0.6571       532\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2360cfd3ffa24177b89e47b765186be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8186    0.5335    0.6460       313\n",
      "           1     0.5549    0.8311    0.6654       219\n",
      "\n",
      "    accuracy                         0.6560       532\n",
      "   macro avg     0.6868    0.6823    0.6557       532\n",
      "weighted avg     0.7101    0.6560    0.6540       532\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3ad8aa57c146208dfa1bd8bb013e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7733    0.6102    0.6821       313\n",
      "           1     0.5719    0.7443    0.6468       219\n",
      "\n",
      "    accuracy                         0.6654       532\n",
      "   macro avg     0.6726    0.6773    0.6645       532\n",
      "weighted avg     0.6904    0.6654    0.6676       532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test = pd.read_csv('data/golden.csv')\n",
    "real = test['is_cont'].values\n",
    "test_data = test.reset_index(drop=True)\n",
    "testing = MultiLabelDataset(test_data, tokenizer, params['max_len'], t=False)\n",
    "test_params = {'batch_size': params['valid_batch'],\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "testing_loader = DataLoader(testing, **test_params)\n",
    "for i in range(params['epochs']):\n",
    "    model = LMModelClassifier.load_from_checkpoint('/scratch/tr/'+params['model']+'-epoch='+str(i)+'.ckpt')\n",
    "    model.test_preds = []\n",
    "    trainer.test(model=model, test_dataloaders=testing_loader)\n",
    "    print(classification_report(real, model.test_preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preds.pickle','wb') as f:\n",
    "    pickle.dump(model.test_preds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test_preds = []\n",
    "trainer.test(test_dataloaders=testing_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame()\n",
    "# df['id'] = list(range(8001,9001))\n",
    "# df['is_humor'] = list(model.test_preds)\n",
    "# df.to_csv('preds1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(real, model.test_preds, digits=4))\n",
    "# model.test_preds == real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
