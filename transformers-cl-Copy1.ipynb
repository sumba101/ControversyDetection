{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code here.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm, neighbors\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, BertConfig, AutoModel\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import pytorch_lightning as pl\n",
    "import neptune\n",
    "import pickle\n",
    "from collections import defaultdict as dd\n",
    "with open(\"token\", \"r\") as f:\n",
    "    token = f.read()\n",
    "# neptune.init(project_qualified_name='tathagataraha/contro-base',\n",
    "#              api_token=token,\n",
    "#              )\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# sent_encoder = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/sent_scores.pickle', 'rb') as f:\n",
    "    tmp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent = dd(0.5)\n",
    "# for i in tmp:\n",
    "#     sent[i[0]] = i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentsum = 0\n",
    "for i in tmp:\n",
    "    sentsum += i[1]\n",
    "sentavg = sentsum/(len(tmp))\n",
    "sent = dd(lambda: sentavg)\n",
    "sent_scores = dd(lambda: sentsum/(len(tmp)))\n",
    "for i in tmp:\n",
    "    sent[i[0]] = i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sent:\n",
    "    if sent[i]>1000:\n",
    "        print(sent[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['bert-base-uncased','roberta-base', 'vinai/bertweet-base']\n",
    "labels = ['is_cont', 'humor_rating', 'humor_controversy', 'offense_rating']\n",
    "model_num = 1\n",
    "label_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'model' : models[model_num],\n",
    "    'label' : labels[label_num],\n",
    "    'valid_size' : 0.2,\n",
    "    'rnd' : 42,\n",
    "    'max_len' : 64,\n",
    "    'train_batch' : 32,\n",
    "    'valid_batch' : 32,\n",
    "    'epochs' : 4,\n",
    "    'lr' : 1e-05,\n",
    "    'dropout' : 0.1,\n",
    "    'pers' : False,\n",
    "    'sent': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'roberta-base',\n",
       " 'label': 'is_cont',\n",
       " 'valid_size': 0.2,\n",
       " 'rnd': 42,\n",
       " 'max_len': 64,\n",
       " 'train_batch': 32,\n",
       " 'valid_batch': 32,\n",
       " 'epochs': 4,\n",
       " 'lr': 1e-05,\n",
       " 'dropout': 0.1,\n",
       " 'pers': False,\n",
       " 'sent': True}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(params['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['TOXICITY_WHOLE', 'TOXICITY_RAW', 'SEVERE_TOXICITY_WHOLE', 'SEVERE_TOXICITY_RAW', 'IDENTITY_ATTACK_WHOLE', 'IDENTITY_ATTACK_RAW', 'INSULT_WHOLE', 'INSULT_RAW', 'PROFANITY_WHOLE', 'PROFANITY_RAW', 'THREAT_WHOLE', 'THREAT_RAW', 'SEXUALLY_EXPLICIT_WHOLE', 'SEXUALLY_EXPLICIT_RAW', 'OBSCENE_WHOLE', 'OBSCENE_RAW'])\n"
     ]
    }
   ],
   "source": [
    "# train = pd.read_csv('data/dataset.csv')\n",
    "import pickle\n",
    "with open('data/complete.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "with open('data/perspective_complete.pickle','rb') as f:\n",
    "    pers_scores = pickle.load(f)\n",
    "    print(pers_scores.keys())\n",
    "# valid = pd.read_csv('data/public_dev.csv')\n",
    "# train = pd.concat([train, valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.DataFrame.from_dict(data).rename(columns = {'tweet_raw_text':'text', 'task_1':'is_cont'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((86975, 16), 80765)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, list(pers_scores['TOXICITY_WHOLE'].keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1353, 1323)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parents = df[df['parent_ID'] == '-1']\n",
    "comments = df[df['parent_ID'] != '-1']\n",
    "pdict = parents.reset_index(drop=True).to_dict()\n",
    "new = dd()\n",
    "values = dd()\n",
    "for i in range(len(pdict['tweet_id'])):\n",
    "    parent = pdict['tweet_id'][i]\n",
    "    tmp = comments[comments['parent_ID']==parent]\n",
    "    new[parent] = tmp.text.values\n",
    "    values[parent] = pdict['is_cont'][i]\n",
    "#     tmp1.append(tmp.shape[0])\n",
    "#     break\n",
    "ones = 0\n",
    "zeros = 0\n",
    "for i in values.keys():\n",
    "    if values[i] == '1':\n",
    "        ones += 1\n",
    "    else:\n",
    "        zeros += 1\n",
    "ones, zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80772"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "counts = []\n",
    "for i in new.keys():\n",
    "    tmp = []\n",
    "    for j in new[i]:\n",
    "        if '&gt' not in j or j.strip() != '':\n",
    "            tmp.append([count, j])\n",
    "            count += 1\n",
    "    counts.append(len(tmp))\n",
    "    new[i] = tmp\n",
    "#     print(new[i])\n",
    "#     break\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1369058597699809291',\n",
       " dict_keys(['tweet_id', 'is_cont', 'full_tweet', 'text', 'hashtags', 'smiley', 'emoji', 'url', 'mentions', 'numerals', 'reserved_word', 'emotext', 'segmented_hash', 'user_ID', 'root_ID', 'parent_ID']),\n",
       " [[31468,\n",
       "   \"Me wondering if 'good lad' Andrew is a 'exalted blessing' according to Morgan\"],\n",
       "  [31469,\n",
       "   'if Diana was alive today, Markle would not have got in the palace door!'],\n",
       "  [31470, 'The truth hurts'],\n",
       "  [31471,\n",
       "   'Is that the the great friend of Donald Trump and regular attendee at parties thrown by Jeffery Epstein???'],\n",
       "  [31472,\n",
       "   'Who cares what Piers Morgan thinks... Prince Harry &amp; Meghan spoke their minds and truth about the Monarchy...and how they were feeling. They are both human beings and deserve a life of freedom.'],\n",
       "  [31473,\n",
       "   'why should I care what Piers thinks? I have my own opinion. I believe Meghan and Harry.'],\n",
       "  [31474,\n",
       "   \"Piers Morgan is a bully and a horrible person and hopefully soon we won't have to see the horrible little man on tv anymore\"],\n",
       "  [31475,\n",
       "   'Hes right, a disgraceful betrayal by the Royal family and palace establishment to protect a newcomer because of her skin tone.'],\n",
       "  [31476, \"Hacked anyone's phones this week? You are a disgrace. sack him.\"],\n",
       "  [31477, 'He would'],\n",
       "  [31478,\n",
       "   \"A disgraceful betrayal is hacking a murdered girl's phone while her parents think she's still alive.\"],\n",
       "  [31479, 'Who can or should waste time with ?'],\n",
       "  [31480, 'She is a total &amp;fake'],\n",
       "  [31481,\n",
       "   \"after we have finished with the mountbattens, piers morgan's neck can be next beneath the guillotine, it should still be warm.\"],\n",
       "  [31482, 'I think him and Susanna Reid are disgraceful'],\n",
       "  [31483,\n",
       "   'IKR- \"the firm\" betrayed common decency, morality, and compassion without breaking a sweat.'],\n",
       "  [31484,\n",
       "   'why you using this bad screenshot? you have an agenda bby we all see it, youre vile'],\n",
       "  [31485,\n",
       "   'Why are the uk press busy questioning every1 about racist remarks but are totally ignoring all the stories they wrote day in day out'],\n",
       "  [31486,\n",
       "   'who gives a S****t what piers Morgan think. Hes another racist like the rest of them'],\n",
       "  [31487,\n",
       "   'He should get a grip. They have every right to express themselves and to be listened to. We all do!'],\n",
       "  [31488, 'Vile British press'],\n",
       "  [31489,\n",
       "   'Hi, please check out my gig if you need any kind of graphic design'],\n",
       "  [31490,\n",
       "   \"Recently my friend's baby was diagnosed with acute lymphocytic leukemia &amp; needs a stem cell transplant. Jason &amp; his wife are first-time parents caring for a sick baby &amp; could use some help. If you are in a place to donate or share, it would be appreciated.\"]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdict['tweet_id'][1053], pdict.keys(), new[pdict['tweet_id'][1053]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for i in range(len(pdict['tweet_id'])):\n",
    "    sum_sent = 0\n",
    "    for j in new[pdict['tweet_id'][i]]:\n",
    "        try:\n",
    "            sum_sent += sent[j[0]]\n",
    "        except:\n",
    "            sum_sent += sentavg\n",
    "#         print(sent[j[0]])\n",
    "    sent_scores[i] = sum_sent/len(new[pdict['tweet_id'][i]])\n",
    "#     print(sum_sent, len(new[pdict['tweet_id'][i]]))\n",
    "    cnt += 1\n",
    "#     if cnt == 10: \n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22081698008114473"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['TOXICITY_WHOLE', 'SEVERE_TOXICITY_WHOLE', 'IDENTITY_ATTACK_WHOLE', 'INSULT_WHOLE', 'PROFANITY_WHOLE', 'THREAT_WHOLE', 'SEXUALLY_EXPLICIT_WHOLE', 'OBSCENE_WHOLE'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict as dd\n",
    "def dflt():\n",
    "    return -1\n",
    "deleted = []\n",
    "for i in pers_scores.keys():\n",
    "    if len(pers_scores[i]) == 0:\n",
    "        deleted.append(i)\n",
    "    else:\n",
    "        pers_scores[i] = dd(dflt, pers_scores[i])\n",
    "for i in deleted:\n",
    "    pers_scores.pop(i)\n",
    "print(pers_scores.keys())\n",
    "final_scores = {\n",
    "    'ids' : [],\n",
    "    'targets' : [],\n",
    "    'scores' : [],\n",
    "    'parent' : [],\n",
    "    'sent' : []\n",
    "}\n",
    "prnt_cnt = 0\n",
    "for i in new.keys():\n",
    "    comments_score = []\n",
    "    cmt_count = 0\n",
    "    for j in new[i]:\n",
    "        if pers_scores['TOXICITY_WHOLE'][j[0]]!= -1:\n",
    "            cmt_count += 1\n",
    "            tmp1 = []\n",
    "            for k in pers_scores.keys():\n",
    "                tmp1.append(pers_scores[k][j[0]])\n",
    "            comments_score.append(tmp1)\n",
    "    comments_score = np.array(comments_score)\n",
    "    final_scores['ids'].append(i)\n",
    "    final_scores['targets'].append(values[i])\n",
    "    mn = np.mean(comments_score, axis=0)\n",
    "    if mn.shape!=(8,):\n",
    "        mn = np.array([0] * 8)\n",
    "    final_scores['scores'].append(mn)\n",
    "    final_scores['sent'].append(sent_scores[prnt_cnt])\n",
    "    final_scores['parent'].append(pdict['text'][prnt_cnt])\n",
    "    prnt_cnt += 1\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>targets</th>\n",
       "      <th>scores</th>\n",
       "      <th>parent</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1376213721568006145</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.1221369183, 0.0559302568, 0.0720628692, 0.0...</td>\n",
       "      <td>Friendship is Always Better Than Relationship ...</td>\n",
       "      <td>0.220817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1376208370135273475</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.16244625920689656, 0.0748024928275862, 0.09...</td>\n",
       "      <td>Friendship is Always Better Than Relationship ...</td>\n",
       "      <td>0.202802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1376190866130280461</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.27947397323529405, 0.1383523302352941, 0.17...</td>\n",
       "      <td>I heard frm a cousin dat famly membrs r mockin...</td>\n",
       "      <td>0.197203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1376188572022153217</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.3174494186153846, 0.1685325290769231, 0.193...</td>\n",
       "      <td>Please Report and Block This PR Bahan Time to ...</td>\n",
       "      <td>0.149427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1376173435785601029</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.2449906602, 0.11239089075, 0.1557814657, 0....</td>\n",
       "      <td>Antilia case is also a high profile case with ...</td>\n",
       "      <td>0.179665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>1378623262486372355</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.2042153005, 0.11953716121428573, 0.13868204...</td>\n",
       "      <td>Mukhtar Ansari did not eat yesterday night. He...</td>\n",
       "      <td>0.544267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>1378616670155988998</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.1855257770555555, 0.11055643825000003, 0.12...</td>\n",
       "      <td>BSP leader will be lodged in barrack number of...</td>\n",
       "      <td>0.153426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>1378616226427981827</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.26946719613636366, 0.18065712163636372, 0.1...</td>\n",
       "      <td>Pic : How we see UP Police. Pic : How gangster...</td>\n",
       "      <td>0.202820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>1378616121046097920</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.2062484501818182, 0.1309215622727273, 0.144...</td>\n",
       "      <td>Why are Punjab police do gently wheeling Mukht...</td>\n",
       "      <td>0.439323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>1378614326911660033</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.2014956974, 0.1306576892, 0.181356530400000...</td>\n",
       "      <td>UP Police leaves Ropar Jail with Gangster turn...</td>\n",
       "      <td>0.107305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2676 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ids targets  \\\n",
       "0     1376213721568006145       1   \n",
       "1     1376208370135273475       1   \n",
       "2     1376190866130280461       1   \n",
       "3     1376188572022153217       1   \n",
       "4     1376173435785601029       1   \n",
       "...                   ...     ...   \n",
       "2671  1378623262486372355       0   \n",
       "2672  1378616670155988998       0   \n",
       "2673  1378616226427981827       0   \n",
       "2674  1378616121046097920       0   \n",
       "2675  1378614326911660033       0   \n",
       "\n",
       "                                                 scores  \\\n",
       "0     [0.1221369183, 0.0559302568, 0.0720628692, 0.0...   \n",
       "1     [0.16244625920689656, 0.0748024928275862, 0.09...   \n",
       "2     [0.27947397323529405, 0.1383523302352941, 0.17...   \n",
       "3     [0.3174494186153846, 0.1685325290769231, 0.193...   \n",
       "4     [0.2449906602, 0.11239089075, 0.1557814657, 0....   \n",
       "...                                                 ...   \n",
       "2671  [0.2042153005, 0.11953716121428573, 0.13868204...   \n",
       "2672  [0.1855257770555555, 0.11055643825000003, 0.12...   \n",
       "2673  [0.26946719613636366, 0.18065712163636372, 0.1...   \n",
       "2674  [0.2062484501818182, 0.1309215622727273, 0.144...   \n",
       "2675  [0.2014956974, 0.1306576892, 0.181356530400000...   \n",
       "\n",
       "                                                 parent      sent  \n",
       "0     Friendship is Always Better Than Relationship ...  0.220817  \n",
       "1     Friendship is Always Better Than Relationship ...  0.202802  \n",
       "2     I heard frm a cousin dat famly membrs r mockin...  0.197203  \n",
       "3     Please Report and Block This PR Bahan Time to ...  0.149427  \n",
       "4     Antilia case is also a high profile case with ...  0.179665  \n",
       "...                                                 ...       ...  \n",
       "2671  Mukhtar Ansari did not eat yesterday night. He...  0.544267  \n",
       "2672  BSP leader will be lodged in barrack number of...  0.153426  \n",
       "2673  Pic : How we see UP Police. Pic : How gangster...  0.202820  \n",
       "2674  Why are Punjab police do gently wheeling Mukht...  0.439323  \n",
       "2675  UP Police leaves Ropar Jail with Gangster turn...  0.107305  \n",
       "\n",
       "[2676 rows x 5 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.DataFrame(final_scores)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.31793552, 0.1926329 , 0.19398184, 0.3156712 , 0.17824667,\n",
       "        0.23254247, 0.10227367, 0.15558852]),\n",
       " [[31468,\n",
       "   \"Me wondering if 'good lad' Andrew is a 'exalted blessing' according to Morgan\"],\n",
       "  [31469,\n",
       "   'if Diana was alive today, Markle would not have got in the palace door!'],\n",
       "  [31470, 'The truth hurts'],\n",
       "  [31471,\n",
       "   'Is that the the great friend of Donald Trump and regular attendee at parties thrown by Jeffery Epstein???'],\n",
       "  [31472,\n",
       "   'Who cares what Piers Morgan thinks... Prince Harry &amp; Meghan spoke their minds and truth about the Monarchy...and how they were feeling. They are both human beings and deserve a life of freedom.'],\n",
       "  [31473,\n",
       "   'why should I care what Piers thinks? I have my own opinion. I believe Meghan and Harry.'],\n",
       "  [31474,\n",
       "   \"Piers Morgan is a bully and a horrible person and hopefully soon we won't have to see the horrible little man on tv anymore\"],\n",
       "  [31475,\n",
       "   'Hes right, a disgraceful betrayal by the Royal family and palace establishment to protect a newcomer because of her skin tone.'],\n",
       "  [31476, \"Hacked anyone's phones this week? You are a disgrace. sack him.\"],\n",
       "  [31477, 'He would'],\n",
       "  [31478,\n",
       "   \"A disgraceful betrayal is hacking a murdered girl's phone while her parents think she's still alive.\"],\n",
       "  [31479, 'Who can or should waste time with ?'],\n",
       "  [31480, 'She is a total &amp;fake'],\n",
       "  [31481,\n",
       "   \"after we have finished with the mountbattens, piers morgan's neck can be next beneath the guillotine, it should still be warm.\"],\n",
       "  [31482, 'I think him and Susanna Reid are disgraceful'],\n",
       "  [31483,\n",
       "   'IKR- \"the firm\" betrayed common decency, morality, and compassion without breaking a sweat.'],\n",
       "  [31484,\n",
       "   'why you using this bad screenshot? you have an agenda bby we all see it, youre vile'],\n",
       "  [31485,\n",
       "   'Why are the uk press busy questioning every1 about racist remarks but are totally ignoring all the stories they wrote day in day out'],\n",
       "  [31486,\n",
       "   'who gives a S****t what piers Morgan think. Hes another racist like the rest of them'],\n",
       "  [31487,\n",
       "   'He should get a grip. They have every right to express themselves and to be listened to. We all do!'],\n",
       "  [31488, 'Vile British press'],\n",
       "  [31489,\n",
       "   'Hi, please check out my gig if you need any kind of graphic design'],\n",
       "  [31490,\n",
       "   \"Recently my friend's baby was diagnosed with acute lymphocytic leukemia &amp; needs a stem cell transplant. Jason &amp; his wife are first-time parents caring for a sick baby &amp; could use some help. If you are in a place to donate or share, it would be appreciated.\"]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scores['scores'][1053], new[final_scores['ids'][1053]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# # train_x, valid_x, train_y, valid_y = model_selection.train_test_split(train['tweet'], train['label'])\n",
    "# train_x, valid_x, train_y, valid_y = train_test_split(train.text, train[params['label']], test_size=params['valid_size'], random_state=params['rnd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    try:\n",
    "        return len(text.split())\n",
    "    except:\n",
    "        print(text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total = 0\n",
    "# maxw = 0\n",
    "# large_count = 0\n",
    "# for i in train.text:\n",
    "#     temp = count_words(i)\n",
    "#     total += temp\n",
    "#     maxw = temp if temp > maxw else maxw\n",
    "#     large_count += 1 if temp > 64 else 0\n",
    "# total/len(train.text), maxw, large_count, len(train.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def to_int(i):\n",
    "#     return int(i)\n",
    "# train.is_cont = train.is_cont.apply(to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len, t = False):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.parent\n",
    "        self.pers_scores = dataframe.scores\n",
    "        self.sent_scores = dataframe.sent\n",
    "#         self.emoji = dataframe.emoji\n",
    "#         self.hash = dataframe.segmented_hash\n",
    "        self.t = t\n",
    "        if not self.t:\n",
    "            self.targets = self.data.targets\n",
    "        self.max_len = max_len\n",
    "#         print(self.targets)\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        pers = self.pers_scores[index]\n",
    "        sent = self.sent_scores[index]\n",
    "        text = \" \".join(text.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask = True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "#         h_text = self.hash[index]\n",
    "#         h_text = \" \".join(h_text)\n",
    "#         inputs = self.tokenizer.encode_plus(\n",
    "#             h_text,\n",
    "#             None,\n",
    "#             truncation=True,\n",
    "#             add_special_tokens=True,\n",
    "#             max_length=self.max_len,\n",
    "#             pad_to_max_length=True,\n",
    "#             return_attention_mask = True,\n",
    "#             return_token_type_ids=True\n",
    "#         )\n",
    "#         h_ids = inputs['input_ids']\n",
    "#         h_mask = inputs['attention_mask']\n",
    "#         h_token_type_ids = inputs[\"token_type_ids\"]\n",
    "#         h_inputs\n",
    "#         emoji = getEmojiEmbeddings(self.emoji[index])\n",
    "        if self.t:\n",
    "            return {\n",
    "                'ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'mask': torch.tensor(mask, dtype=torch.long),\n",
    "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "                'pers_scores': torch.tensor(pers, dtype=torch.float),\n",
    "                'sent' : torch.tensor(sent, dtype=torch.float),\n",
    "#                 'h_ids': torch.tensor(h_ids, dtype=torch.long),\n",
    "#                 'h_mask': torch.tensor(h_mask, dtype=torch.long),\n",
    "#                 'h_token_type_ids': torch.tensor(h_token_type_ids, dtype=torch.long),\n",
    "#                 'emoji' : torch.tensor(emoji, dtype=torch.long),\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'mask': torch.tensor(mask, dtype=torch.long),\n",
    "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "                'pers_scores': torch.tensor(pers, dtype=torch.float),\n",
    "                'sent_scores' : torch.tensor(sent, dtype=torch.float).reshape([-1]),\n",
    "#                 'h_ids': torch.tensor(h_ids, dtype=torch.long),\n",
    "#                 'h_mask': torch.tensor(h_mask, dtype=torch.long),\n",
    "#                 'h_token_type_ids': torch.tensor(h_token_type_ids, dtype=torch.long),\n",
    "#                 'emoji' : torch.tensor(emoji, dtype=torch.long),\n",
    "                'targets': torch.tensor(int(self.targets[index]), dtype=torch.long)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (2676, 5)\n",
      "TRAIN Dataset: (2141, 5)\n",
      "TEST Dataset: (535, 5)\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "# train_size = 0.85\n",
    "train_data=train.sample(frac=1 - params['valid_size'],random_state=params['rnd'])\n",
    "test_data=train.drop(train_data.index).reset_index(drop=True)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "# train_data, test_data = train_test_split(train, test_size=params['valid_size'])\n",
    "\n",
    "test_data=test_data.reset_index(drop=True)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "def intify(x):\n",
    "    return int(x)\n",
    "print(\"FULL Dataset: {}\".format(train.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_data.shape))\n",
    "test_real = test_data.targets.apply(intify).values\n",
    "training_set = MultiLabelDataset(train_data, tokenizer, params['max_len'])\n",
    "testing_set = MultiLabelDataset(test_data, tokenizer, params['max_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in train_data['scores'].values:\n",
    "    if i.shape != (8,):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0]*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': params['train_batch'],\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': params['valid_batch'],\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([32, 64]) torch.Size([32, 8]) torch.Size([32, 1])\n",
      "torch.Size([29, 64]) torch.Size([29, 8]) torch.Size([29, 1])\n",
      "{'ids': tensor([[    0, 18691,  1557,  ...,     1,     1,     1],\n",
      "        [    0,   113,   100,  ...,     1,     1,     1],\n",
      "        [    0, 16636,   637,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0,  4148,     5,  ...,     1,     1,     1],\n",
      "        [    0,  3762,    11,  ...,     1,     1,     1],\n",
      "        [    0, 42633,  7033,  ...,     1,     1,     1]]), 'mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'pers_scores': tensor([[0.2878, 0.1351, 0.1937, 0.2968, 0.1477, 0.1439, 0.0889, 0.2009],\n",
      "        [0.2407, 0.1354, 0.1186, 0.2299, 0.1688, 0.1240, 0.1112, 0.2402],\n",
      "        [0.3082, 0.1761, 0.1640, 0.3040, 0.2168, 0.1258, 0.0741, 0.1193],\n",
      "        [0.3656, 0.2047, 0.2304, 0.3149, 0.2446, 0.1909, 0.3241, 0.2815],\n",
      "        [0.1551, 0.0823, 0.0885, 0.1268, 0.1103, 0.1617, 0.1026, 0.2262],\n",
      "        [0.2104, 0.1018, 0.1174, 0.2002, 0.1373, 0.1155, 0.0701, 0.2639],\n",
      "        [0.1476, 0.0764, 0.0913, 0.1027, 0.1482, 0.1414, 0.2076, 0.1229],\n",
      "        [0.1703, 0.0820, 0.1013, 0.1372, 0.0993, 0.1746, 0.0864, 0.2416],\n",
      "        [0.2247, 0.1122, 0.1532, 0.2142, 0.1112, 0.1286, 0.0664, 0.1833],\n",
      "        [0.1187, 0.0693, 0.0764, 0.0675, 0.0982, 0.1582, 0.1147, 0.1522],\n",
      "        [0.2037, 0.1186, 0.1295, 0.1775, 0.0995, 0.3180, 0.0769, 0.2131],\n",
      "        [0.2901, 0.1323, 0.1266, 0.2839, 0.1669, 0.1558, 0.0956, 0.2012],\n",
      "        [0.1917, 0.1067, 0.1047, 0.1558, 0.1246, 0.1816, 0.1194, 0.2129],\n",
      "        [0.3087, 0.1391, 0.2168, 0.3194, 0.1484, 0.1736, 0.0698, 0.2056],\n",
      "        [0.2252, 0.1206, 0.1844, 0.1978, 0.1170, 0.2322, 0.0872, 0.1856],\n",
      "        [0.1946, 0.1120, 0.1114, 0.1482, 0.1543, 0.1743, 0.1162, 0.2164],\n",
      "        [0.1936, 0.0944, 0.1108, 0.1703, 0.1148, 0.1774, 0.0652, 0.1068],\n",
      "        [0.1955, 0.1544, 0.0944, 0.1465, 0.1864, 0.2212, 0.2078, 0.1620],\n",
      "        [0.4322, 0.2793, 0.2425, 0.4181, 0.3205, 0.1981, 0.1560, 0.3363],\n",
      "        [0.2877, 0.1723, 0.2325, 0.2984, 0.1935, 0.1786, 0.0898, 0.1958],\n",
      "        [0.0691, 0.0327, 0.0425, 0.0374, 0.0539, 0.1072, 0.1075, 0.2258],\n",
      "        [0.1527, 0.0769, 0.1088, 0.1258, 0.0810, 0.1514, 0.0970, 0.1717],\n",
      "        [0.1616, 0.1004, 0.1107, 0.1027, 0.0993, 0.1855, 0.1163, 0.1509],\n",
      "        [0.2586, 0.1232, 0.0900, 0.2502, 0.1470, 0.2181, 0.0691, 0.1830],\n",
      "        [0.1648, 0.0973, 0.1292, 0.1437, 0.0957, 0.1059, 0.0829, 0.1234],\n",
      "        [0.1943, 0.1023, 0.1017, 0.1271, 0.1476, 0.1708, 0.1341, 0.2807],\n",
      "        [0.1828, 0.0885, 0.0647, 0.1295, 0.0770, 0.1915, 0.0530, 0.1727],\n",
      "        [0.1453, 0.0639, 0.0819, 0.1313, 0.0811, 0.1124, 0.0564, 0.0809],\n",
      "        [0.1364, 0.0798, 0.0773, 0.0949, 0.1049, 0.1495, 0.1034, 0.1497]]), 'sent_scores': tensor([[0.4497],\n",
      "        [0.5858],\n",
      "        [0.5981],\n",
      "        [0.4114],\n",
      "        [0.4637],\n",
      "        [0.5740],\n",
      "        [0.0336],\n",
      "        [0.1834],\n",
      "        [0.3007],\n",
      "        [0.5005],\n",
      "        [0.5582],\n",
      "        [0.3268],\n",
      "        [0.4787],\n",
      "        [0.0989],\n",
      "        [0.5087],\n",
      "        [0.4403],\n",
      "        [0.5581],\n",
      "        [0.2342],\n",
      "        [0.5026],\n",
      "        [0.4200],\n",
      "        [0.6346],\n",
      "        [0.5164],\n",
      "        [0.3857],\n",
      "        [0.2655],\n",
      "        [0.2361],\n",
      "        [0.3790],\n",
      "        [0.6452],\n",
      "        [0.3047],\n",
      "        [0.4947]]), 'targets': tensor([1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 1, 1, 0])}\n"
     ]
    }
   ],
   "source": [
    "it = iter(training_loader)\n",
    "while True:\n",
    "    try:\n",
    "        hel = next(it)\n",
    "    except:\n",
    "        print(hel)\n",
    "        break\n",
    "    print(hel['ids'].shape, hel['pers_scores'].shape, hel['sent_scores'].shape)\n",
    "#     print(hel['ids'].shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModelClassifier(pl.LightningModule):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.l1 = AutoModel.from_pretrained(params['model'])\n",
    "        self.pre_classifier_1 = torch.nn.Linear(768, 768)\n",
    "        self.final_layer_dim = 768\n",
    "        if params['pers']:\n",
    "            self.pre_classifier_2 = torch.nn.Linear(8, 8)\n",
    "            self.final_layer_dim += 8\n",
    "        if params['sent']:\n",
    "#             self.pre_classifier_3 = torch.nn.Linear(8, 8)\n",
    "            self.final_layer_dim += 1\n",
    "        self.pre_classifier_x = torch.nn.Linear(self.final_layer_dim, self.final_layer_dim)\n",
    "        self.dropout = torch.nn.Dropout(params['dropout'])\n",
    "        self.total_loss = 0\n",
    "        self.batch_count = 0\n",
    "        self.epoch = 0\n",
    "        self.classifier = torch.nn.Linear(self.final_layer_dim, 2)\n",
    "        self.preds = []\n",
    "        self.targets = []\n",
    "        self.test_preds = []\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, pers, sent):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state_1 = output_1[0]\n",
    "        pooler_1 = hidden_state_1[:, 0]\n",
    "        pooler_1 = self.pre_classifier_1(pooler_1)\n",
    "        pooler_1 = torch.nn.Tanh()(pooler_1)\n",
    "        pooler_1 = self.dropout(pooler_1)\n",
    "#         pre_final1 = self.classifier(pooler_1)\n",
    "        if params['pers']:\n",
    "            pooler_2 = self.pre_classifier_2(pers)\n",
    "            pooler_2 = torch.nn.Tanh()(pooler_2)\n",
    "            pooler_2 = self.dropout(pooler_2)\n",
    "            pooler_1 = torch.cat((pooler_1, pooler_2), 1)\n",
    "        if params['sent']:\n",
    "            pooler_1 = torch.cat((pooler_1, sent), 1)\n",
    "        if params['sent'] or params['pers']:\n",
    "            pooler_1 = self.pre_classifier_x(pooler_1)\n",
    "            pooler_1 = torch.nn.Tanh()(pooler_1)\n",
    "            pooler_1 = self.dropout(pooler_1)\n",
    "        output = self.classifier(pooler_1)\n",
    "        return output\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params =  self.parameters(), lr=params['lr'])\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        ids = batch['ids']\n",
    "        mask = batch['mask']\n",
    "        token_type_ids = batch['token_type_ids']\n",
    "        pers = batch['pers_scores']\n",
    "        sent = batch['sent_scores']\n",
    "        targets = batch['targets']\n",
    "        outputs = self.forward(ids, mask, token_type_ids, pers, sent)\n",
    "        loss = torch.nn.CrossEntropyLoss()(outputs, targets)\n",
    "        self.total_loss += loss\n",
    "        self.batch_count += 1\n",
    "        logger_logs = {'training_loss': loss}\n",
    "        logger_logs = {'losses': logger_logs} # optional (MUST ALL BE TENSORS)\n",
    "        output = {\n",
    "            'loss': loss, # required\n",
    "            'progress_bar': {'training_loss': loss}, # optional (MUST ALL BE TENSORS)\n",
    "            'log': logger_logs\n",
    "        }\n",
    "        # return a dict\n",
    "        return output\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.epoch += 1\n",
    "        print(f'Epoch: {self.epoch}, Loss:  {self.total_loss/self.batch_count}')\n",
    "        self.total_loss=0\n",
    "        self.batch_count=0\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        ids = batch['ids']\n",
    "        mask = batch['mask']\n",
    "        token_type_ids = batch['token_type_ids']\n",
    "        pers = batch['pers_scores']\n",
    "        sent = batch['sent_scores']\n",
    "        targets = batch['targets']\n",
    "        outputs = self.forward(ids, mask, token_type_ids, pers, sent)\n",
    "        loss = torch.nn.CrossEntropyLoss()(outputs, targets)\n",
    "        labels_hat = torch.argmax(outputs, dim=1)\n",
    "        self.preds.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "        self.targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "        val_acc = torch.sum(targets == labels_hat).item() / (len(targets) * 1.0)\n",
    "        output = {\n",
    "            'val_loss': loss,\n",
    "            'val_acc': torch.tensor(val_acc), # everything must be a tensor\n",
    "        }\n",
    "        return output\n",
    "    \n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        self.preds = list(np.argmax(np.array(self.preds), axis=1).flatten())\n",
    "        print(classification_report(self.targets, self.preds, digits=4))\n",
    "        self.preds = []\n",
    "        self.targets = []\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        ids = batch['ids']\n",
    "        mask = batch['mask']\n",
    "        token_type_ids = batch['token_type_ids']\n",
    "        pers = batch['pers_scores']\n",
    "        outputs = self.forward(ids, mask, token_type_ids, pers)\n",
    "        labels_hat = torch.argmax(outputs, dim=1)\n",
    "        self.test_preds.extend(labels_hat.cpu().detach().numpy().tolist())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath='/scratch/tr/',\n",
    "    filename=params['model']+'-{epoch}',\n",
    "    save_top_k = -1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    }
   ],
   "source": [
    "model = LMModelClassifier(params)\n",
    "trainer = pl.Trainer(max_epochs=params['epochs'], callbacks=[checkpoint_callback], gpus=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name             | Type         | Params\n",
      "--------------------------------------------------\n",
      "0 | l1               | RobertaModel | 124 M \n",
      "1 | pre_classifier_1 | Linear       | 590 K \n",
      "2 | pre_classifier_x | Linear       | 592 K \n",
      "3 | dropout          | Dropout      | 0     \n",
      "4 | classifier       | Linear       | 1.5 K \n",
      "--------------------------------------------------\n",
      "125 M     Trainable params\n",
      "0         Non-trainable params\n",
      "125 M     Total params\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7969    1.0000    0.8870        51\n",
      "           1     0.0000    0.0000    0.0000        13\n",
      "\n",
      "    accuracy                         0.7969        64\n",
      "   macro avg     0.3984    0.5000    0.4435        64\n",
      "weighted avg     0.6350    0.7969    0.7068        64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad7f12c0aea4090a0951ddb5e4a866c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The {progress_bar:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
      "Please use self.log(...) inside the lightningModule instead.\n",
      "\n",
      "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
      "# (inside LightningModule)\n",
      "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
      "Please use self.log(...) inside the lightningModule instead.\n",
      "\n",
      "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
      "# (inside LightningModule)\n",
      "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8299    0.9522    0.8868       251\n",
      "           1     0.9514    0.8275    0.8851       284\n",
      "\n",
      "    accuracy                         0.8860       535\n",
      "   macro avg     0.8906    0.8898    0.8860       535\n",
      "weighted avg     0.8944    0.8860    0.8859       535\n",
      "\n",
      "Epoch: 1, Loss:  0.577275812625885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The {progress_bar:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
      "Please use self.log(...) inside the lightningModule instead.\n",
      "\n",
      "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
      "# (inside LightningModule)\n",
      "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
      "Please use self.log(...) inside the lightningModule instead.\n",
      "\n",
      "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
      "# (inside LightningModule)\n",
      "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8736    0.9363    0.9038       251\n",
      "           1     0.9398    0.8803    0.9091       284\n",
      "\n",
      "    accuracy                         0.9065       535\n",
      "   macro avg     0.9067    0.9083    0.9065       535\n",
      "weighted avg     0.9088    0.9065    0.9066       535\n",
      "\n",
      "Epoch: 2, Loss:  0.28121399879455566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The {progress_bar:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
      "Please use self.log(...) inside the lightningModule instead.\n",
      "\n",
      "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
      "# (inside LightningModule)\n",
      "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
      "Please use self.log(...) inside the lightningModule instead.\n",
      "\n",
      "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
      "# (inside LightningModule)\n",
      "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8764    0.9323    0.9035       251\n",
      "           1     0.9366    0.8838    0.9094       284\n",
      "\n",
      "    accuracy                         0.9065       535\n",
      "   macro avg     0.9065    0.9080    0.9064       535\n",
      "weighted avg     0.9083    0.9065    0.9066       535\n",
      "\n",
      "Epoch: 3, Loss:  0.19404827058315277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The {progress_bar:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
      "Please use self.log(...) inside the lightningModule instead.\n",
      "\n",
      "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
      "# (inside LightningModule)\n",
      "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
      "Please use self.log(...) inside the lightningModule instead.\n",
      "\n",
      "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
      "# (inside LightningModule)\n",
      "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8185    0.9522    0.8803       251\n",
      "           1     0.9506    0.8134    0.8767       284\n",
      "\n",
      "    accuracy                         0.8785       535\n",
      "   macro avg     0.8846    0.8828    0.8785       535\n",
      "weighted avg     0.8886    0.8785    0.8784       535\n",
      "\n",
      "Epoch: 4, Loss:  0.1468270719051361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader=training_loader, val_dataloaders=testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testdf = pd.read_csv('data/final_golden.csv')\n",
    "# with open('data/extracted_golden.pickle', 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "# test = pd.DataFrame.from_dict(data)[['tweet_raw_text', 'task_1']].rename(columns = {'tweet_raw_text':'text', 'task_1':'is_cont'})\n",
    "# test['is_cont'] = testdf['is_cont']\n",
    "# test.is_cont = test.is_cont.apply(to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test['is_cont'] == testdf['is_cont']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfba81fee76f4d6b94783b7470eb92aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8464    0.9442    0.8927       251\n",
      "           1     0.9451    0.8486    0.8942       284\n",
      "\n",
      "    accuracy                         0.8935       535\n",
      "   macro avg     0.8958    0.8964    0.8935       535\n",
      "weighted avg     0.8988    0.8935    0.8935       535\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6abd918e63f1419783c18813bffda314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8667    0.9323    0.8983       251\n",
      "           1     0.9358    0.8732    0.9035       284\n",
      "\n",
      "    accuracy                         0.9009       535\n",
      "   macro avg     0.9013    0.9028    0.9009       535\n",
      "weighted avg     0.9034    0.9009    0.9010       535\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6272ceb8eb47e2896366d1c02f34c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8839    0.9402    0.9112       251\n",
      "           1     0.9440    0.8908    0.9167       284\n",
      "\n",
      "    accuracy                         0.9140       535\n",
      "   macro avg     0.9140    0.9155    0.9139       535\n",
      "weighted avg     0.9158    0.9140    0.9141       535\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a50c7fbe0f4b37809d4e5a7c0033c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagata.raha/anaconda/envs/p3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8203    0.9641    0.8864       251\n",
      "           1     0.9625    0.8134    0.8817       284\n",
      "\n",
      "    accuracy                         0.8841       535\n",
      "   macro avg     0.8914    0.8888    0.8841       535\n",
      "weighted avg     0.8958    0.8841    0.8839       535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test = pd.read_csv('data/golden.csv')\n",
    "# real = test['is_cont'].values\n",
    "# test_data = test.reset_index(drop=True)\n",
    "# testing = MultiLabelDataset(test_data, tokenizer, params['max_len'], t=False)\n",
    "# test_params = {'batch_size': params['valid_batch'],\n",
    "#                 'shuffle': False,\n",
    "#                 'num_workers': 0\n",
    "#                 }\n",
    "# testing_loader = DataLoader(testing, **test_params)\n",
    "for i in range(params['epochs']):\n",
    "    model = LMModelClassifier.load_from_checkpoint('/scratch/tr/'+params['model']+'-epoch='+str(i)+'.ckpt')\n",
    "    model.test_preds = []\n",
    "    trainer.test(model=model, test_dataloaders=testing_loader)\n",
    "    print(classification_report(test_real, model.test_preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preds.pickle','wb') as f:\n",
    "    pickle.dump(model.test_preds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test_preds = []\n",
    "trainer.test(test_dataloaders=testing_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame()\n",
    "# df['id'] = list(range(8001,9001))\n",
    "# df['is_humor'] = list(model.test_preds)\n",
    "# df.to_csv('preds1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(real, model.test_preds, digits=4))\n",
    "# model.test_preds == real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
